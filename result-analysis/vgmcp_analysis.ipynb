{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de43470d-9b77-416d-b2de-f561b393949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import models\n",
    "import random\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import pomegranate\n",
    "from scipy import stats\n",
    "from pomegranate.distributions import *\n",
    "\n",
    "\n",
    "from resVAE import bentoVAE\n",
    "from utils import galmen_rubin, draw_choice, vae_recface, EarlyStopper\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de23377-71c6-4200-9db7-461b5b9f797a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa68031-8dc0-4829-8415-520b8890d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL connection is closed!\n"
     ]
    }
   ],
   "source": [
    "# full-guidance data\n",
    "try:\n",
    "    engine = create_engine('postgresql://dallinger:dallinger@localhost:5432/vgmcp-rd1')\n",
    "    table = \"\"\"select * from participant\"\"\"\n",
    "    participant = pd.read_sql_query(table,con=engine)\n",
    "    table = \"\"\"select * from info\"\"\"\n",
    "    info = pd.read_sql_query(table,con=engine)\n",
    "    table = \"\"\"select * from node\"\"\"\n",
    "    node = pd.read_sql_query(table,con=engine)\n",
    "    table = \"\"\"select * from network\"\"\"\n",
    "    network = pd.read_sql_query(table,con=engine)\n",
    "finally:\n",
    "    #closing database connection.\n",
    "    if engine:\n",
    "        engine.dispose()\n",
    "        print(\"PostgreSQL connection is closed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b07c425-7e38-41ff-9914-99ca34b3bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.sort_values(by=['network_id', 'origin_id'], inplace=True)\n",
    "mcmcp = info[(info['network_id']>150) & (info['network_id']<=len(network)-3)]\n",
    "mcmcp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "catch = info[info['network_id']>len(network)-3]\n",
    "catch.reset_index(drop=True, inplace=True)\n",
    "\n",
    "probe = info[info['network_id']<=150]\n",
    "probe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3c649c-70ed-42d4-a45a-064025c92170",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_vgmcp = {}\n",
    "chain_names = ['happy', 'sad', 'neutral']\n",
    "for p in range(len(participant)):\n",
    "    catch_vgmcp[f'subject_{p+1}_catch_happy'] = []\n",
    "    catch_vgmcp[f'subject_{p+1}_catch_sad'] = []\n",
    "    catch_vgmcp[f'subject_{p+1}_catch_neutral'] = []\n",
    "\n",
    "    for net_id in [len(network)-2, len(network)-1, len(network)]:\n",
    "        node_id = node[(node['network_id']==net_id) & (node['participant_id']==p+1)]['id'].values\n",
    "        if len(node_id) == 2:\n",
    "            catch_info = catch[(catch['origin_id'] == node_id[0]) | (catch['origin_id'] == node_id[1])]\n",
    "            catch_info = catch_info[catch_info['property1'] == 'True']\n",
    "            catch_info.reset_index(drop=True, inplace=True)\n",
    "            for i in range(len(catch_info)):\n",
    "                catch_vgmcp[f'subject_{p+1}_catch_{chain_names[net_id-len(network)+2]}'].append(json.loads(catch_info.loc[i, 'contents'])['face'].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b5e4dd-6a4c-4025-9540-1b814fa4f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included participants are [4, 5, 7, 8, 9, 11, 13, 15, 17, 19]\n"
     ]
    }
   ],
   "source": [
    "# catch_pca\n",
    "# attention check\n",
    "included_p = []\n",
    "for p in range(len(participant)): \n",
    "    score = 0\n",
    "    for chosen in catch_vgmcp[f'subject_{p+1}_catch_happy']:\n",
    "        if chosen == 'left.png':\n",
    "            score += 1\n",
    "    for chosen in catch_vgmcp[f'subject_{p+1}_catch_sad']:\n",
    "        if chosen == 'right.png':\n",
    "            score += 1\n",
    "    for chosen in catch_vgmcp[f'subject_{p+1}_catch_neutral']:\n",
    "        if chosen == 'left.png':\n",
    "            score += 1\n",
    "    if score == 6:\n",
    "        included_p.append(p+1)\n",
    "print('Included participants are', included_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b07f305-0b4b-4b30-93cc-94a840563a8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data 1\n",
    "trace_vgmcp = {}\n",
    "chain_names = ['happy_1', 'happy_2', 'sad_1', 'sad_2', 'neutral_1', 'neutral_2']\n",
    "for p in included_p:\n",
    "    trace_vgmcp[f'subject_{p}_happy_1'] = []\n",
    "    trace_vgmcp[f'subject_{p}_happy_2'] = []\n",
    "    trace_vgmcp[f'subject_{p}_sad_1'] = []\n",
    "    trace_vgmcp[f'subject_{p}_sad_2'] = []\n",
    "    trace_vgmcp[f'subject_{p}_neutral_1'] = []\n",
    "    trace_vgmcp[f'subject_{p}_neutral_2'] = []\n",
    "for net_id in range(151, len(network)-2):\n",
    "    p = (net_id-151)//6 + 1\n",
    "    if p in included_p:\n",
    "        chain_id = (net_id-151)%6\n",
    "        chain_data = mcmcp[mcmcp['network_id']==net_id]\n",
    "        chain_data = chain_data.sort_values(by=['id'])\n",
    "        chain_data.reset_index(drop=True, inplace=True)\n",
    "        for info_id in range(len(chain_data)):\n",
    "            if info_id%2 == 1:\n",
    "                for _ in range(chain_data.loc[info_id+1, 'details']):\n",
    "                # for _ in range(1):\n",
    "                    trace_vgmcp[f'subject_{p}_{chain_names[chain_id]}'].append(json.loads(chain_data.loc[info_id, 'contents'])['loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1515252-455d-48a7-bed2-1e67bd43bba0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data 2\n",
    "chain_names = ['happy_1', 'happy_2', 'sad_1', 'sad_2', 'neutral_1', 'neutral_2']\n",
    "for p in included_p:\n",
    "    trace_vgmcp[f'study2_subject_{p}_happy_1'] = []\n",
    "    trace_vgmcp[f'study2_subject_{p}_happy_2'] = []\n",
    "    trace_vgmcp[f'study2_subject_{p}_sad_1'] = []\n",
    "    trace_vgmcp[f'study2_subject_{p}_sad_2'] = []\n",
    "    trace_vgmcp[f'study2_subject_{p}_neutral_1'] = []\n",
    "    trace_vgmcp[f'study2_subject_{p}_neutral_2'] = []\n",
    "for net_id in range(151, 391):\n",
    "    p = (net_id-151)//6 + 1\n",
    "    if p in included_p:\n",
    "        chain_id = (net_id-151)%6\n",
    "        chain_data = mcmcp[mcmcp['network_id']==net_id]\n",
    "        chain_data = chain_data.sort_values(by=['id'])\n",
    "        chain_data.reset_index(drop=True, inplace=True)\n",
    "        for info_id in range(len(chain_data)):\n",
    "            if info_id%2 == 1:\n",
    "                for _ in range(chain_data.loc[info_id+1, 'details']):\n",
    "                    trace_vgmcp[f'study2_subject_{p}_{chain_names[chain_id]}'].append(json.loads(chain_data.loc[info_id, 'contents'])['loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec370e-2e12-45f1-804b-3d5b31f50221",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('samples_vgmcp.npy', trace_vgmcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e897531-0279-48e6-8bed-731aa7875fc2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## main analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb1e6ba-1a5c-434e-983d-b65176f3726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "trace_vgmcp = np.load('secondary-data/samples_vgmcp.npy', allow_pickle='TRUE').item()\n",
    "# trace_vgmcp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd2e2e-b77a-4a18-8356-a67a69c178fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-hat\n",
    "r_hat_cov = 0\n",
    "length_chain = []\n",
    "r_hats = np.zeros((int(len(trace_vgmcp.keys())/6), 3))\n",
    "for i in range(0, len(trace_vgmcp.keys()), 2):\n",
    "    length_chain.append((len(list(trace_vgmcp.values())[i]) + len(list(trace_vgmcp.values())[i+1]))/2)\n",
    "    r_hats[i//6, int((i%6)/2)] = galmen_rubin(list(trace_vgmcp.values())[i], list(trace_vgmcp.values())[i+1])\n",
    "    if r_hats[i//6, int((i%6)/2)] < 1.11:\n",
    "        r_hat_cov += 1\n",
    "mean_across_emo = np.mean(r_hats, 1)\n",
    "print(length_chain)\n",
    "print('The covergence rate is:', r_hat_cov/(len(trace_vgmcp.keys())/2))\n",
    "# np.save('rhat_vgmcp.npy', r_hats)\n",
    "print('All R_hats are (row-participant, column-emo):\\n', r_hats)\n",
    "print(\"R_hats' mean and standard error across emo:\\n\", \n",
    "      np.mean(mean_across_emo), '+-', np.std(mean_across_emo, ddof=1) / np.sqrt(len(mean_across_emo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5778a3a-c352-486a-ac0c-a04753598516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-hat\n",
    "# r_hats_t = np.zeros((int(len(trace_vgmcp.keys())/6), 3, 1500))\n",
    "# for i in range(0, len(trace_vgmcp.keys()), 2):\n",
    "#     # length_chain.append((len(list(trace_vgmcp.values())[i]) + len(list(trace_vgmcp.values())[i+1]))/2)\n",
    "#     for t in range(1, min(len(list(trace_vgmcp.values())[i]), len(list(trace_vgmcp.values())[i+1]))):\n",
    "#         r_hats_t[i//6, int((i%6)/2), t] = galmen_rubin(list(trace_vgmcp.values())[i][:t], list(trace_vgmcp.values())[i+1][:t])\n",
    "\n",
    "# np.save('rhat_vgmcp_t.npy', r_hats_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da6f143-21ea-41a2-b57e-94fc93f663a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace plot 3-d\n",
    "id = 2  # 1-18\n",
    "emo = 'sad'\n",
    "\n",
    "if emo == 'happy':\n",
    "    chain1_id = (id-1)*6 + 0\n",
    "    chain2_id = (id-1)*6 + 1\n",
    "elif emo == 'sad':\n",
    "    chain1_id = (id-1)*6 + 2\n",
    "    chain2_id = (id-1)*6 + 3\n",
    "elif emo == 'neutral':\n",
    "    chain1_id = (id-1)*6 + 4\n",
    "    chain2_id = (id-1)*6 + 5\n",
    "\n",
    "draw_choice(list(trace_vgmcp.values())[chain1_id], \n",
    "            list(trace_vgmcp.values())[chain2_id], \n",
    "            title='VAE-guided-sub1-happy', label='on', plot_range=[-8, 8])\n",
    "# probe trials\n",
    "# mapping experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0680e1-4ff3-41f8-863c-d10167b66515",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"vae_model/seed13_KL02(decoder).pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993868ed-4a58-4c6e-b37f-fd64d5b39f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(trace_vgmcp.values())[1]\n",
    "input_tensor = torch.tensor(data).float()\n",
    "reconstructed_face = vae_recface(model, input_tensor, mode='cumulative', index=len(data)-1)  # single or cumulative\n",
    "plt.imshow(reconstructed_face, cmap='gray')\n",
    "plt.axis('off')\n",
    "## show serial face during the sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f68e0-ee47-450e-9eec-ca84195464f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = [1, 100, 300, 500, len(data)-1]\n",
    "fig = plt.figure(figsize=(5., 20.))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1, len(serie)), axes_pad=0.0)\n",
    "for idx, (ax, im) in enumerate(zip(grid, [vae_recface(model, data, mode='cumulative', index=i) for i in serie])):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.set_title(f\"{serie[idx]}\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4a2043-2bef-48ac-9060-2e085e8890e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 39.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine the 2 chains\n",
    "id = 5  # 1-18\n",
    "emo = 'happy'\n",
    "\n",
    "if emo == 'happy':\n",
    "    chain1_id = (id-1)*6 + 0\n",
    "    chain2_id = (id-1)*6 + 1\n",
    "elif emo == 'sad':\n",
    "    chain1_id = (id-1)*6 + 2\n",
    "    chain2_id = (id-1)*6 + 3\n",
    "elif emo == 'neutral':\n",
    "    chain1_id = (id-1)*6 + 4\n",
    "    chain2_id = (id-1)*6 + 5\n",
    "\n",
    "data = list(trace_vgmcp.values())[chain1_id] + list(trace_vgmcp.values())[chain2_id]\n",
    "\n",
    "reconstructed_face = vae_recface(model, data, mode='cumulative', index=len(data)-1)  # single or cumulative\n",
    "plt.imshow(reconstructed_face, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fb7655-058a-45cd-be0c-375fd83b35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover weighted human representation\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def model_pdf(x, emotion):\n",
    "    if emotion == \"happy\":\n",
    "        covariance = np.array([[1.51, -0.21, -0.01], [-0.21, 1.10, 0.19], [0, 0.19, 1.14]])\n",
    "        mean = np.array([3.0, -3.13, -2.78])\n",
    "    elif emotion == \"sad\":\n",
    "        covariance = np.array([[2.07, -0.38, -0.70], [-0.38, 1.17, -0.47], [-0.70, -0.47, 1.25]])\n",
    "        mean = np.array([-0.69, 1.80, 1.78])\n",
    "    else:\n",
    "        covariance = np.array([[1.62, 0.43, -0.28], [0.43, 1.05, 0.02], [-0.28, 0.02, 1.21]])\n",
    "        mean = np.array([1.70, 2.43, -0.48])\n",
    "\n",
    "    dt = multivariate_normal(mean=mean, cov=covariance)\n",
    "\n",
    "    return dt.pdf(x)\n",
    "\n",
    "def weight_vae(x, emotion):\n",
    "    weight = 1/np.sqrt(model_pdf(x, emotion))\n",
    "\n",
    "    if weight <= 10000:\n",
    "        return weight\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def weighted_cum(data, index, emo):\n",
    "    if index == 0:\n",
    "        index = len(data)\n",
    "    weights = []\n",
    "    for sample in data[:index]:\n",
    "        weights.append(weight_vae(sample, emo))\n",
    "    weights_sum = np.sum(weights)\n",
    "    weighted_mean = np.zeros(3)\n",
    "    for i in range(index):\n",
    "        weighted_mean += np.array(data[i]) * weights[i]/weights_sum\n",
    "    return weighted_mean, weights/weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c007839-c40c-400e-beef-87563ef75c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1  # 1-18\n",
    "emo = 'sad'\n",
    "\n",
    "if emo == 'happy':\n",
    "    chain1_id = (id-1)*6 + 0\n",
    "    chain2_id = (id-1)*6 + 1\n",
    "elif emo == 'sad':\n",
    "    chain1_id = (id-1)*6 + 2\n",
    "    chain2_id = (id-1)*6 + 3\n",
    "elif emo == 'neutral':\n",
    "    chain1_id = (id-1)*6 + 4\n",
    "    chain2_id = (id-1)*6 + 5\n",
    "\n",
    "data = list(trace_vgmcp.values())[chain2_id]\n",
    "l = len(data)\n",
    "serie = [1, int(l/20), int(l/4), int(l/2), int(l*3/4), l]\n",
    "fig = plt.figure(figsize=(5., 20.))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1, len(serie)), axes_pad=0.0)\n",
    "for idx, (ax, im) in enumerate(zip(grid, [model(torch.tensor(weighted_cum(data, i, emo)[0]).float())[0, 0, :, :] * 255 for i in serie])):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    if idx == 0:\n",
    "        ax.set_title(f'{serie[idx]}')\n",
    "    else:\n",
    "        ax.set_title(f\"{int((serie[idx]+1)*200/len(data))}\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14161eb-bb1b-49e9-8dda-4398b6b791b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the 2 chains\n",
    "emo = 'neutral'\n",
    "fig = plt.figure(figsize=(15., 20.))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1, 23), axes_pad=0.0)\n",
    "\n",
    "for id in range(1, 24):\n",
    "    if emo == 'happy':\n",
    "        chain1_id = (id-1)*6 + 0\n",
    "        chain2_id = (id-1)*6 + 1\n",
    "    elif emo == 'sad':\n",
    "        chain1_id = (id-1)*6 + 2\n",
    "        chain2_id = (id-1)*6 + 3\n",
    "    elif emo == 'neutral':\n",
    "        chain1_id = (id-1)*6 + 4\n",
    "        chain2_id = (id-1)*6 + 5\n",
    "        \n",
    "    data = list(trace_vgmcp.values())[chain1_id] + list(trace_vgmcp.values())[chain2_id]\n",
    "    reconstructed_face = model(torch.tensor(weighted_cum(data, len(data)-1, emo)[0]).float())[0, 0, :, :] * 255\n",
    "    # plt.imsave(f\"./vgmcp/{emo}/{id}.png\", reconstructed_face, cmap='gray')\n",
    "    grid[id-1].imshow(reconstructed_face, cmap='gray')\n",
    "    grid[id-1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeae0c3-77bf-48c1-a229-b359bf80c6f3",
   "metadata": {},
   "source": [
    "## probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067f555-f2cb-49da-b060-59fcac5a9898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418160ea-0706-4223-936f-a0341faf392d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a610b2-d321-41ef-9f09-79ab63f0dd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d567fee-1224-4425-89df-03b445af4dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c768d18-67cb-47c2-a755-9bede49b85ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444b4f0-b87b-406b-a6e3-247357186506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de521891-125c-425d-bbb5-568585f3239c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95a7d2-2960-4421-ac49-692051b450b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
